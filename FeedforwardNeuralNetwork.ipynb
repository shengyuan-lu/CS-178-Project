{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedforward Neural Network ON Fashion-MINIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.mnist_reader as mnist_reader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# Disable ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Fashion-MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mnist_reader.load_mnist('data/fashion', kind='train')\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.25, random_state=seed, shuffle=True) # Train Test Split used for training purposes\n",
    "\n",
    "X_te, y_te = mnist_reader.load_mnist('data/fashion', kind='t10k') # The actual evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Set')\n",
    "print(X_tr.shape) # 45000 rows, each row has 784 columns can be arranged in 28 * 28\n",
    "print(y_tr.shape) # 45000 classifications\n",
    "\n",
    "print('\\nValuation Set')\n",
    "print(X_val.shape) # 15000 rows, each row has 784 columns can be arranged in 28 * 28\n",
    "print(y_val.shape) # 15000 classifications\n",
    "\n",
    "print('\\nTest Set')\n",
    "print(X_te.shape) # 10000 rows, each row has 784 columns can be arranged in 28 * 28\n",
    "print(y_te.shape) # 10000 classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "\n",
    "X_tr = scaler.transform(X_tr)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_te = scaler.transform(X_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the best parameters with `GridSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for tuning\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (50,50)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.01]\n",
    "}\n",
    "\n",
    "training_amount = 15000 # valid amounts are between 0 and 45000\n",
    "\n",
    "# Create the MLP classifier\n",
    "mlp = MLPClassifier(random_state=seed)\n",
    "\n",
    "# Perform grid search to find the best parameters\n",
    "grid_search = GridSearchCV(mlp, param_grid, cv=5)\n",
    "grid_search.fit(X_tr[:training_amount], y_tr[:training_amount])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best parameters and score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Create the table to display the results\n",
    "fig, ax = plt.subplots(figsize=(20, 2))\n",
    "ax.axis('off')\n",
    "\n",
    "table_data = [str(best_params), str(best_score)]\n",
    "\n",
    "parameter_names = sorted(list(best_params.keys()))\n",
    "parameter_values = [best_params[key] for key in parameter_names]\n",
    "\n",
    "table = ax.table(cellText=[parameter_values], colLabels=parameter_names, cellLoc='center', loc='center')\n",
    "\n",
    "# Set the table style\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(12)\n",
    "table.scale(1.5, 1.5)\n",
    "\n",
    "plt.title('Best Hyper Parameters')\n",
    "plt.show()\n",
    "\n",
    "print(f'Best Accuracy Score: {best_score}')\n",
    "\n",
    "df = pd.DataFrame(grid_search.cvresults)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a `MLPClassifier` with the best parameters found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the MLP classifier with the best parameters\n",
    "# mlp_best = MLPClassifier(activation='relu', alpha=0.0001, hidden_layer_sizes=(50,), solver='sgd', random_state=seed)\n",
    "mlp_best = MLPClassifier(**best_params, random_state=seed)\n",
    "mlp_best.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate accuracy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_pred = mlp_best.predict(X_tr)\n",
    "y_val_pred = mlp_best.predict(X_val)\n",
    "y_test_pred = mlp_best.predict(X_te)\n",
    "\n",
    "acc_tr = accuracy_score(y_tr, y_tr_pred)\n",
    "acc_val = accuracy_score(y_val, y_val_pred)\n",
    "acc_te = accuracy_score(y_te, y_test_pred)\n",
    "\n",
    "print(f\"The MLP Classifier Has Training Accuracy: {acc_tr}\")\n",
    "print(f\"The MLP Classifier Has Validation Accuracy: {acc_val}\")\n",
    "print(f\"The MLP Classifier Has Testing Accuracy: {acc_te}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_te, y_test_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = cm)\n",
    "disp = disp.plot(include_values=True, cmap='viridis', ax=None, xticks_rotation='horizontal')\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2desc = {0: 'T-shirt/top (label 0)',\n",
    "              1: 'Trouser (label 1)',\n",
    "              2: 'Pullover (label 2)',\n",
    "              3: 'Dress (label 3)',\n",
    "              4: 'Coat (label 4)',\n",
    "              5: 'Sandal (label 5)',\n",
    "              6: 'Shirt (label 6)',\n",
    "              7: 'Sneaker (label 7)',\n",
    "              8: 'Bag (label 8)',\n",
    "              9: 'Ankle boot (label 9)'}\n",
    "\n",
    "report = classification_report(y_te, y_test_pred, target_names = label2desc.values(), output_dict=True)\n",
    "\n",
    "sns.heatmap(pd.DataFrame(report).iloc[:-1, :].T, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Learning Curve"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mlp_train_errors = []\n",
    "mlp_test_errors = []\n",
    "\n",
    "n_tr = [100, 1000, 5000, 10000, 20000, 45000]\n",
    "\n",
    "for n in n_tr:\n",
    "\n",
    "    # Get a sub portion of feature vectors\n",
    "    sub_X_tr = X_tr[:n]\n",
    "    sub_y_tr = y_tr[:n]\n",
    "\n",
    "    # MLPClassifier\n",
    "    mlp = MLPClassifier(activation='relu', alpha=0.0001, hidden_layer_sizes=(50,), solver='sgd', random_state=seed)\n",
    "\n",
    "    mlp.fit(sub_X_tr, sub_y_tr)\n",
    "\n",
    "    mlp_train_pred = mlp.predict(X_tr)\n",
    "    mlp_test_pred = mlp.predict(X_te)\n",
    "\n",
    "    mlp_train_error = 1 - accuracy_score(y_tr, mlp_train_pred)\n",
    "    mlp_test_error = 1 - accuracy_score(y_te, mlp_test_pred)\n",
    "\n",
    "    mlp_train_errors.append(mlp_train_error)\n",
    "    mlp_test_errors.append(mlp_test_error)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(n_tr, mlp_test_errors, 'o-', label='MLP Testing Error')\n",
    "plt.plot(n_tr, mlp_train_errors, 'o--', label='MLP Training Error')\n",
    "\n",
    "plt.xlabel('Number of Training Data Points')\n",
    "plt.ylabel('Error Rate')\n",
    "plt.xscale('log')\n",
    "plt.title('Relation Between Amount Of Training Data and Error Rate')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
